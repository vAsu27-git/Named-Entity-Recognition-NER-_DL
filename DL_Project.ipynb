{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Project.ipynb","provenance":[],"authorship_tag":"ABX9TyNt6ZnYltiyDeVoy+ya2nip"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"wXJjjRQmACuE","executionInfo":{"status":"ok","timestamp":1637675670530,"user_tz":-330,"elapsed":1146,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}},"outputId":"8ce5535f-0849-4cab-d47e-3d8d49b05a9f"},"source":["import pandas as pd\n","data = pd.read_csv('/content/drive/MyDrive/ner_dataset.csv', encoding= 'unicode_escape')\n","data.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"NIeWxmbSAReI","executionInfo":{"status":"ok","timestamp":1637675672552,"user_tz":-330,"elapsed":416,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}}},"source":["from itertools import chain\n","def get_dict_map(data, token_or_tag):\n","    tok2idx = {}\n","    idx2tok = {}\n","    \n","    if token_or_tag == 'token':\n","        vocab = list(set(data['Word'].to_list()))\n","    else:\n","        vocab = list(set(data['Tag'].to_list()))\n","    \n","    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n","    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n","    return tok2idx, idx2tok\n","token2idx, idx2token = get_dict_map(data, 'token')\n","tag2idx, idx2tag = get_dict_map(data, 'tag')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6zhwvF6AXMX","executionInfo":{"status":"ok","timestamp":1637675685620,"user_tz":-330,"elapsed":8802,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}},"outputId":"28186d23-6a3c-4a17-9cbf-7d3f11cc079c"},"source":["data['Word_idx'] = data['Word'].map(token2idx)\n","data['Tag_idx'] = data['Tag'].map(tag2idx)\n","data_fillna = data.fillna(method='ffill', axis=0)\n","# Groupby and collect columns\n","data_group = data_fillna.groupby(\n","['Sentence #'],as_index=False\n",")['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  import sys\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMDwNmrGAchP","executionInfo":{"status":"ok","timestamp":1637675694227,"user_tz":-330,"elapsed":7004,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}},"outputId":"6fc4981a-7254-419d-b0a0-7a385ec834ea"},"source":["from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","def get_pad_train_test_val(data_group, data):\n","\n","    #get max token and tag length\n","    n_token = len(list(set(data['Word'].to_list())))\n","    n_tag = len(list(set(data['Tag'].to_list())))\n","\n","    #Pad tokens (X var)    \n","    tokens = data_group['Word_idx'].tolist()\n","    maxlen = max([len(s) for s in tokens])\n","    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n","\n","    #Pad Tags (y var) and convert it into one hot encoding\n","    tags = data_group['Tag_idx'].tolist()\n","    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n","    n_tags = len(tag2idx)\n","    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n","    \n","    #Split train, test and validation set\n","    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n","    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n","\n","    print(\n","        'train_tokens length:', len(train_tokens),\n","        '\\ntrain_tokens length:', len(train_tokens),\n","        '\\ntest_tokens length:', len(test_tokens),\n","        '\\ntest_tags:', len(test_tags),\n","        '\\nval_tokens:', len(val_tokens),\n","        '\\nval_tags:', len(val_tags),\n","    )\n","    \n","    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\n","\n","train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data_group, data)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["train_tokens length: 32372 \n","train_tokens length: 32372 \n","test_tokens length: 4796 \n","test_tags: 4796 \n","val_tokens: 10791 \n","val_tags: 10791\n"]}]},{"cell_type":"code","metadata":{"id":"F3nYExEjA1dq","executionInfo":{"status":"ok","timestamp":1637675694228,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}}},"source":["import numpy as np\n","import tensorflow\n","from tensorflow.keras import Sequential, Model, Input\n","from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n","from tensorflow.keras.utils import plot_model\n","from numpy.random import seed\n","seed(1)\n","tensorflow.random.set_seed(2)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"fpHfxoV8A384","executionInfo":{"status":"ok","timestamp":1637675694230,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}}},"source":["input_dim = len(list(set(data['Word'].to_list())))+1\n","output_dim = 64\n","input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n","n_tags = len(tag2idx)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6Vq6c2DA7pw","executionInfo":{"status":"ok","timestamp":1637675695776,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}}},"source":["def get_bilstm_lstm_model():\n","    model = Sequential()\n","\n","    # Add Embedding layer\n","    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n","\n","    # Add bidirectional LSTM\n","    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n","\n","    # Add LSTM\n","    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n","\n","    # Add timeDistributed Layer\n","    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n","\n","    #Optimiser \n","    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n","\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n","    \n","    return model"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFynp7P_A9Qn","executionInfo":{"status":"ok","timestamp":1637675695776,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}}},"source":["def train_model(X, y, model):\n","    loss = list()\n","    for i in range(5):\n","        # fit model for one epoch on this sequence\n","        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n","        loss.append(hist.history['loss'][0])\n","    return loss"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJD-ibM_A-1B","executionInfo":{"status":"ok","timestamp":1637676717808,"user_tz":-330,"elapsed":1020560,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}},"outputId":"38230baf-7db1-4ce8-b455-2f07062d0709"},"source":["results = pd.DataFrame()\n","model_bilstm_lstm = get_bilstm_lstm_model()\n","plot_model(model_bilstm_lstm)\n","results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 104, 64)           2251456   \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 104, 128)         66048     \n"," l)                                                              \n","                                                                 \n"," lstm_1 (LSTM)               (None, 104, 64)           49408     \n","                                                                 \n"," time_distributed (TimeDistr  (None, 104, 17)          1105      \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 2,368,017\n","Trainable params: 2,368,017\n","Non-trainable params: 0\n","_________________________________________________________________\n","26/26 [==============================] - 155s 6s/step - loss: 0.7013 - accuracy: 0.9300 - val_loss: 0.2625 - val_accuracy: 0.9681\n","26/26 [==============================] - 144s 6s/step - loss: 0.2656 - accuracy: 0.9678 - val_loss: 0.3701 - val_accuracy: 0.9683\n","26/26 [==============================] - 143s 5s/step - loss: 0.2994 - accuracy: 0.9676 - val_loss: 0.2299 - val_accuracy: 0.9683\n","26/26 [==============================] - 143s 5s/step - loss: 0.2141 - accuracy: 0.9678 - val_loss: 0.1735 - val_accuracy: 0.9682\n","26/26 [==============================] - 143s 5s/step - loss: 0.1827 - accuracy: 0.9678 - val_loss: 0.1658 - val_accuracy: 0.9682\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"v-C-lkqnBAy2","executionInfo":{"status":"ok","timestamp":1637682089233,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Vasu Hudka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4EamLwlWMSzpbeiy-l1PjWeizwUiiCvZN-XjLIw=s64","userId":"06047414749191757668"}},"outputId":"e8797fb4-4777-4f24-c5cb-5e5997e2c46a"},"source":["import spacy\n","from spacy import displacy\n","nlp = spacy.load('en_core_web_sm')\n","text = nlp('Hi, My name is Vasu \\n I am from India \\n I want to work with Google \\n Steve Jobs is My Inspiration')\n","displacy.render(text, style = 'ent', jupyter=True)"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi, My name is \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Vasu\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," </br> I am from \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    India\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," </br> I want to work with \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Google\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," </br> \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Steve Jobs\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," is My Inspiration</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]}]}